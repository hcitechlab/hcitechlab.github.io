<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta name="description" content="Human-Centered Interactive Technologies Lab" />
        <title>HCI Tech Lab</title>
        <link rel="shortcut icon" type="image/x-icon" href="assets/main_icon.PNG" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
        <link rel="stylesheet" href="css/styles.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter&family=Share+Tech&display=swap" rel="stylesheet">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Rubik&display=swap" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="css/styles.css">
        <link rel="stylesheet" href="css/hcitech.css">
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-L11CDKTS4E"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-L11CDKTS4E');
        </script>
    </head>

    <body id="page-top">
        <!-- Header-->
            <!-- Navigation-->
            <div class="container">
                <nav class="navbar navbar-expand-lg navbar-light bg-light px-4">
                    <a class="navbar-brand" href="index.html">
                        <img alt ="logo" src="assets/main_logo.PNG" class="logo d-none d-sm-block">
                        <img alt ="logo" src="assets/main_letter.PNG" class="logo d-block d-sm-none">
                    </a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon"></span>
                    </button>

                    <div class="collapse navbar-collapse" id="navbarResponsive">
                        <ul class="navbar-nav ms-auto">
                            <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="publication.html">Publications</a></li>
                            <li class="nav-item"><a class="nav-link" href="team.html">Team</a></li>
                            <li class="nav-item"><a class="nav-link" href="course.html">Courses</a></li>
                            <li class="nav-item"><a class="nav-link" href="join.html">Join Us</a></li>
                            <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
                        </ul>
                    </div>
                </nav>
            </div>

        <!-- Publication section-->
        <div class="container">
            <div id = "publications" class="row">
                <div class="col-lg-12">
                    <div class="card h-100">
                        <div class="card-body">
                            <h2 class="card-title">Publications</h2>

                            <!-- Publication List-->
                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research//SoundGuided/Sound-guided-CVPR.jpg">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h4><b>Sound-Guided Semantic Image Manipulation</h4>
                                    <h6><b>AUTHORS</b> Seunghyun Lee, Wonseok Roh, Wonmin Byeon, Sang Ho Yoon, Chanyoung Kim, Jinkyu Kim*, Sangpil Kim*</a></h6>
                                    <h6><b>TO APPEAR</b>  <a class="link-success" href="https://cvpr2022.thecvf.com/" target="_blank">Conference on Computer Vision and Pattern Recognition (CVPR), 2022</a></h6>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research//SoundGuided/Sound-guided.jpg">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h4><b>Sound-Guided Semantic Image Manipulation</h4>
                                    <h6><b>AUTHORS</b> Seung Hyun Lee, Sang Ho Yoon, Jinkyu Kim*, Sangpil Kim* </a></h6>
                                    <h6><b>IN PROCEEDINGS</b>  <a class="link-success" href="https://ctrlgenworkshop.github.io/" target="_blank">NeurIPS Workshop on CtrlGen: Controllable Generative Modeling in Language and Vision (NIPSW), 2021</a></h6>
                                        <a class="info badge badge-info text-wrap"  href="./research/SoundGuided/Sound-guided semantic image manipulation.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap"  style="width: 7rem" href="./research/SoundGuided/Sound-guided semantic image manipulation supplementary.pdf" target="_blank">Supplemental</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/AudioArt/AudioArt.JPG">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>Audio-Guided Image Manipulation for Artistic Paintings</h5>
                                    <h6><b>AUTHORS</b> Seung Hyun Lee, Nahyuk Lee, Chanyoung Kim, Wonjeong Ryoo Jinkyu Kim , Sang Ho Yoon*, Sangpil Kim*</a></h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://neuripscreativityworkshop.github.io/2021/" target="_blank">NeurIPS Workshop on Machine Learning for Creativity and Design (NIPSW), 2021</a></h6>
                                      <a class="info badge badge-info text-wrap"  href="./research/AudioArt/AudioGuided.pdf" target="_blank">PDF</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/Surfaceflow/Surfaceflow.gif">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>SurfaceFlow: Large Area Haptic Display via Compliant Liquid Dielectric Actuators</h5>
                                    <h6><b>AUTHORS</b> Yitian Shao, Siyuan Ma, Sang Ho Yoon, Yon Visell, James Holbery</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://2020.hapticssymposium.org/" target="_blank">IEEE Haptics Symposium, 2020</a></h6>
                                        <a class="info badge badge-info text-wrap"  href="https://doi.org/10.1109/HAPTICS45997.2020.ras.HAP20.23.0f334629" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap"  href="./research/Surfaceflow/Surfaceflow.pdf" target="_blank">PDF</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/iMold/iMold.PNG">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>iMold: Enabling Interactive Design Optimization for In-Mold Electronics</h5>
                                    <h6><b>AUTHORS</b> Jonathan Ting, Yunbo Zhang, Sang Ho Yoon, James D Holbery, Siyuan Ma</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://chi2020.acm.org/" target="_blank">ACM Conference on Human Factors in Computing Systems Late Breaking Work (CHI LBW), 2020</a></h6>
                                        <a class="info badge badge-info text-wrap"  href="https://doi.org/10.1145/3334480.3382891" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap"  href="./research/iMold/iMold.pdf" target="_blank">PDF</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/StressMonitoring/StressMonitoring.PNG">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>Stress Monitoring using Multimodal Bio-sensing Headset</h5>
                                    <h6><b>AUTHORS</b> Joong Hoon Lee, Hannes Gamper, Ivan Tashev, Steven Dong, Siyuan Ma, Jacquelin Remaley, James D Holbery, Sang Ho Yoon</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://chi2020.acm.org/" target="_blank">ACM Conference on Human Factors in Computing Systems Late Breaking Work (CHI LBW), 2020</a></h6>
                                        <a class="info badge badge-info text-wrap"  href="https://doi.org/10.1145/3334480.3382891" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap"  href="./research/StressMonitoring/StressMonitoring.pdf" target="_blank">PDF</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/Hapsense/Hapsense.png">
                                        <source type="video/mp4" src="./research/Hapsense/Hapsense.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>HapSense: A Soft Haptic I/O Device with Uninterrupted Dual Functionalities of Force Sensing and Vibrotactile Actuation</h5>
                                    <h6><b>AUTHORS</b> Sang Ho Yoon, Woo Suk Lee, Shantanu Thakurdesai, Di Sun, Flávio P. Ribeiro, James D. Holbery</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://uist.acm.org/uist2019" target="_blank">ACM User Interface Software and Technology Symposium (UIST), 2019</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://dl.acm.org/doi/10.1145/3332165.3347888" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/Hapsense/Hapsense.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap" style="width: 4rem" href="https://youtu.be/VpoEI6o3vMA" target="_blank">VIDEO</a>
                                        <a class="info badge badge-info text-wrap" style="width: 7rem" href="https://youtu.be/O3i3IaMdbXg" target="_blank">PRESENTATION</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/MultiSoft/MultiSoft.jpg">
                                        <source type="video/mp4" src="./research/MultiSoft/MultiSoft.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>MultiSoft: Soft Sensor Enabling Real-Time Multimodal Sensing with Contact Localization and Deformation Classification</b></h5>
                                    <h6><b>AUTHORS</b> Sang Ho Yoon, Luis Paredes, Ke Huo, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://www.ubicomp.org/ubicomp2018/" target="_blank"> ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT), 2018</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/3264955" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/MultiSoft/MultiSoft.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap" style ="width: 4rem" href="https://youtu.be/PDgE26cgjG8" target="_blank">VIDEO</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/Scenariot/Scenariot.jpg">
                                        <source type="video/mp4" src="./research/Scenariot/Scenariot.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>Scenariot: Spatially mapping smart things within augmented reality scenes</h5>
                                    <h6><b>AUTHORS</b> Ke Huo, Yuanzhi Cao, Sang Ho Yoon, Zhuangying Xu, Guiming Chen, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://chi2018.acm.org/" target="_blank">ACM Conference on Human Factors in Computing Systems (CHI), 2018</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/3173574.3173793" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/Scenariot/Scenariot.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap" style ="width: 4rem" href="https://youtu.be/DqJsitjEo8E" target="_blank">VIDEO</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/iSoft/iSoft.jpg">
                                        <source type="video/mp4" src="./research/iSoft/iSoft.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>iSoft: A Customizable Soft Sensor with Real-time Continuous Contact and Stretching Sensing</h5>
                                    <h6><b>AUTHORS</b> Sang Ho Yoon, Ke Huo, Yunbo Zhang, Guiming Chen, Luis Paredes, Subramanian Chidambaram, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://uist.acm.org/uist2017" target="_blank">ACM User Interface Software and Technology Symposium (UIST), 2017</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/3126594.3126654" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/iSoft/iSoft.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap" style ="width: 4rem" href="https://youtu.be/JVaYEl9nbME" target="_blank">VIDEO</a>
                                        <a class="info badge badge-info text-wrap" style="width: 7rem;" href="https://youtu.be/_YupB3qLikQ" target="_blank">PRESENTATION</a>
                                        <a class="info badge badge-info text-wrap" style="width: 4rem;" href="https://www.youtube.com/watch?v=7fNbM-lrX-E" target="_blank">MEDIA</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/BikeGesture/BikeGesture.jpg">
                                        <source type="video/mp4" src="./research/BikeGesture/Bikegesture.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>BikeGesture: user elicitation and performance of micro hand gesture as input for cycling</h5>
                                    <h6><b>AUTHORS</b> Yanke Tan*, Sang Ho Yoon*, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://chi2017.acm.org/" target="_blank">ACM Conference on Human Factors in Computing Systems Late Breaking Work (CHI LBW), 2017</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/3027063.3053075" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/BikeGesture/BikeGesture.pdf" target="_blank">PDF</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/TRing/TRing.jpg">
                                        <source type="video/mp4" src="./research/TRing/TRing.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>TRing: Instant and customizable interactions with objects using an embedded magnet and a finger-worn device</b></h5>
                                    <h6><b>AUTHORS</b> Sang Ho Yoon, Ke Huo, Yunbo Zhang, Guiming Chen, Luis Paredes, Subramanian Chidambaram, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://uist.acm.org/uist2016" target="_blank">ACM User Interface Software and Technology Symposium (UIST), 2016</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/2984511.2984529" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/TRing/TRing.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap" style="width: 4rem" href="https://youtu.be/MDS5G7-U9Kk" target="_blank">VIDEO</a>
                                        <a class="info badge badge-info text-wrap" style="width: 7rem" href="https://youtu.be/ruhxaCrznWs" target="_blank">PRESENTATION</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/RobustHand/RobustHand.png">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>Robust hand pose estimation during the interaction with an unknown object</b></h5>
                                     <h6><b>AUTHORS</b> Chiho Choi, Sang Ho Yoon, Chin-Ning Chen, Karthik Ramani</h6>
                                     <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://iccv2017.thecvf.com/" target="_blank"> International Conference on Computer Vision (ICCV), 2017</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1109/ICCV.2017.339" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/RobustHand/RobustHand.pdf" target="_blank">PDF</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/TMotion/TMotion.jpg">
                                        <source type="video/mp4" src="./research/TMotion/TMotion.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>TMotion: Embedded 3D Mobile Input using Magnetic Sensing Technique</b></h5>
                                    <h6><b>AUTHORS</b> Sang Ho Yoon, Ke Huo, Vinh P. Nguyen, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://sigchi.org/conferences/conference-history/tei/tei-2015/" target="_blank"> International Conference on Tangible, Embedded, and Embodied Interaction (TEI), 2016</a></h6>
                                    <h6><b>AWARD </b> ACM UIST Best Poster Award (1st Place, 2015)</h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/2839462.2839463" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/TMotion/TMotion.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap" style ="width: 4rem" href="https://www.youtube.com/watch?v=pWuq5H5kyAg" target="_blank">VIDEO</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/WearableTextileInput/WearableTextileInput.PNG">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>Wearable textile input device with multimodal sensing for eyes-free mobile interaction during daily activities</b></h5>
                                    <h6><b>AUTHORS</b> Sang Ho Yoon, Ke Huo, Karthik Ramani</h6>
                                    <h6><b>IN</b> <a class="link-success" href="https://www.journals.elsevier.com/pervasive-and-mobile-computing" target="_blank"> Pervasive and Mobile Computing, 2016 (SCIE)</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1016/j.pmcj.2016.04.008" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/WearableTextileInput/WearableTextileInput.pdf" target="_blank">PDF</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/TiMMi/TiMMI.jpg">
                                        <source type="video/mp4" src="./research/TiMMi/TiMMi.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>TIMMi: Finger-worn Textile Input Device with Multimodal Sensing in Mobile Interaction</b></h5>
                                    <h6><b>AUTHORS</b> Sang Ho Yoon, Ke Huo, Vinh P. Nguyen, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://sigchi.org/conferences/conference-history/tei/tei-2015/" target="_blank"> International Conference on Tangible, Embedded, and Embodied Interaction (TEI), 2015</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/2677199.2680560" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/TiMMi/TiMMi.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap"  style ="width: 4rem" href="https://youtu.be/rEMBgWGdb-E" target="_blank">VIDEO</a>
                                    </p>
                                </div>
                            </div>

                            <div class = "row research_item">
                                <div class="col-md-3">
                                    <video  class="img-fluid" autoplay loop muted playsinline poster="./research/BendID/BendID.jpg">
                                        <source type="video/mp4" src="./research/BendID/BendID.mp4">
                                    </video>
                                </div>
                                <div class="col-md-9">
                                    <h5><b>BendID: Flexible interface for localized deformation recognition</b></h5>
                                    <h6><b>AUTHORS</b> Vinh P. Nguyen, Sang Ho Yoon, Ansh Verma, Karthik Ramani</h6>
                                    <h6><b>IN PROCEEDINGS</b> <a class="link-success" href="https://www.ubicomp.org/ubicomp2014/" target="_blank">ACM international joint conference on pervasive and ubiquitous computing (UBICOMP), 2014</a></h6>
                                        <a class="info badge badge-info text-wrap" href="https://doi.org/10.1145/2632048.2636092" target="_blank">DOI</a>
                                        <a class="info badge badge-info text-wrap" href="./research/BendID/BendID.pdf" target="_blank">PDF</a>
                                        <a class="info badge badge-info text-wrap" style ="width: 4rem" href="https://youtu.be/8X91vr81mdg" target="_blank">VIDEO</a>
                                    </p>
                                </div>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Footer-->
        <footer class="py-4 bg-black">
            <div class ="container">
                <div class ="row">
                    <div class="col-lg-8 px-4">
                        <h5 class="m-0 text-left text-white" style="font-size:medium"><b>HCI Tech Lab</b></h5>
                        <h5 class="m-0 text-left" style="color:lightgray; font-size: small;">KAIST, N5, Room 2346,<br>
                            291 Daehak-ro, Yuseong-gu, Daejeon (34141) <br>
                            Republic of Korea
                        </h5>
                    </div>
                    <div class="col-lg-4 text-right">
                            <img src="./assets/KAIST_CT_Logo_White.png" style="height:50px"></img>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
